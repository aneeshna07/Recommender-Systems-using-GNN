{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:25:38.758719Z","iopub.status.busy":"2023-04-29T05:25:38.757984Z","iopub.status.idle":"2023-04-29T05:25:49.900681Z","shell.execute_reply":"2023-04-29T05:25:49.899418Z","shell.execute_reply.started":"2023-04-29T05:25:38.758678Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.13.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.4.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install torch"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["PES1UG20CS050 - ANEESH N A \n","PES1UG20CS085 - ASHISH KULKARNI \n","PES1UG20CS097 - AYUSHI SOUMYA\n","PES1UG20CS120 - DEEPTHI DAYANAND"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import random\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from scipy.io import loadmat"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["click_f = loadmat('data/2/rating.mat')['rating']\n","trust_f = loadmat('data/2/trustnetwork.mat')['trustnetwork']"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["click_list = []\n","trust_list = []\n","\n","u_items_list = []\n","u_users_list = []\n","u_users_items_list = []\n","i_users_list = []\n","\n","user_count = 0\n","item_count = 0\n","rate_count = 0"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train samples: 730054, Valid samples: 91256, Test samples: 91256\n"]}],"source":["for x in click_f:\n","    uid = x[0]\n","    iid = x[1]\n","    label = x[2]\n","    user_count = max(user_count, uid)\n","    item_count = max(item_count, iid)\n","    rate_count = max(rate_count, label)\n","    click_list.append([uid, iid, label])\n","\n","pos_list = []\n","for x in click_list:\n","\tpos_list.append((x[0], x[1], x[2]))\n","\n","pos_list = list(set(pos_list))\n","random.shuffle(pos_list)\n","num_test = int(len(pos_list) * 0.1)\n","test_set = pos_list[:num_test]\n","valid_set = pos_list[num_test:2 * num_test]\n","train_set = pos_list[2 * num_test:]\n","print('Train samples: {}, Valid samples: {}, Test samples: {}'.format(len(train_set), len(valid_set), len(test_set)))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["with open('data/2/dataset.pkl', 'wb') as f:\n","\tpickle.dump(train_set, f, pickle.HIGHEST_PROTOCOL)\n","\tpickle.dump(valid_set, f, pickle.HIGHEST_PROTOCOL)\n","\tpickle.dump(test_set, f, pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["train_df = pd.DataFrame(train_set, columns = ['uid', 'iid', 'label'])\n","valid_df = pd.DataFrame(valid_set, columns = ['uid', 'iid', 'label'])\n","test_df = pd.DataFrame(test_set, columns = ['uid', 'iid', 'label'])\n","\n","click_df = pd.DataFrame(click_list, columns = ['uid', 'iid', 'label'])\n","train_df = train_df.sort_values(axis = 0, ascending = True, by = 'uid')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 22167/22167 [00:30<00:00, 733.68it/s] \n"]}],"source":["for user in tqdm(range(user_count + 1)):\n","    user_df = train_df[train_df['uid'] == user]\n","    user_items = user_df['iid'].tolist()\n","    user_ratings = user_df['label'].tolist()\n","    if len(user_items) == 0:\n","        u_items_list.append([(0, 0)])\n","    else:\n","        u_items_list.append([(iid, rating) for iid, rating in zip(user_items, user_ratings)])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 296278/296278 [05:31<00:00, 892.65it/s] \n"]}],"source":["for item in tqdm(range(item_count + 1)):\n","    item_df = train_df[train_df['iid'] == item]\n","    item_users = item_df['uid'].tolist()\n","    item_ratings = item_df['label'].tolist()\n","    if len(item_users) == 0:\n","        i_users_list.append([(0, 0)])\n","    else:\n","        i_users_list.append([(uid, rating) for uid, rating in zip(item_users, item_ratings)])"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["for x in trust_f:\n","    uid = x[0]\n","    fid = x[1]\n","    if uid > user_count or fid > user_count:\n","        continue\n","    trust_list.append([uid, fid])\n","\n","trust_df = pd.DataFrame(trust_list, columns = ['uid', 'fid'])\n","trust_df = trust_df.sort_values(axis = 0, ascending = True, by = 'uid')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 22167/22167 [00:16<00:00, 1378.42it/s]\n"]}],"source":["for user in tqdm(range(user_count + 1)):\n","    user_df = trust_df[trust_df['uid'] == user]\n","    u_users = user_df['fid'].unique().tolist()\n","    if len(u_users) == 0:\n","        u_users_list.append([0])\n","        u_users_items_list.append([[(0, 0)]])\n","    else:\n","        u_users_list.append(u_users)\n","        uu_items = []\n","        for uid in u_users:\n","            uu_items.append(u_items_list[uid])\n","        u_users_items_list.append(uu_items)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["with open('data/2/list.pkl', 'wb') as f:\n","\tpickle.dump(u_items_list, f, pickle.HIGHEST_PROTOCOL)\n","\tpickle.dump(u_users_list, f, pickle.HIGHEST_PROTOCOL)\n","\tpickle.dump(u_users_items_list, f, pickle.HIGHEST_PROTOCOL)\n","\tpickle.dump(i_users_list, f, pickle.HIGHEST_PROTOCOL)\n","\tpickle.dump((user_count, item_count, rate_count), f, pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:25:49.904149Z","iopub.status.busy":"2023-04-29T05:25:49.903738Z","iopub.status.idle":"2023-04-29T05:25:52.524267Z","shell.execute_reply":"2023-04-29T05:25:52.523170Z","shell.execute_reply.started":"2023-04-29T05:25:49.904101Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import random\n","import pickle\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:25:52.527005Z","iopub.status.busy":"2023-04-29T05:25:52.525645Z","iopub.status.idle":"2023-04-29T05:25:52.538553Z","shell.execute_reply":"2023-04-29T05:25:52.535619Z","shell.execute_reply.started":"2023-04-29T05:25:52.526973Z"},"trusted":true},"outputs":[],"source":["class GraphDataset(Dataset):\n","    def __init__(self, data, u_items_list, u_user_list, u_users_items_list, i_users_list):\n","        self.data = data\n","        self.u_items_list = u_items_list\n","        self.u_users_list = u_user_list\n","        self.u_users_items_list = u_users_items_list\n","        self.i_users_list = i_users_list\n","    \n","    def __getitem__(self, index):\n","        uid = self.data[index][0]\n","        iid = self.data[index][1]\n","        label = self.data[index][2]\n","        u_items = self.u_items_list[uid]\n","        u_users = self.u_users_list[uid]\n","        u_users_items = self.u_users_items_list[uid]\n","        i_users = self.i_users_list[iid]\n","\n","        return (uid, iid, label), u_items, u_users, u_users_items, i_users\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:25:52.541643Z","iopub.status.busy":"2023-04-29T05:25:52.541257Z","iopub.status.idle":"2023-04-29T05:25:52.560268Z","shell.execute_reply":"2023-04-29T05:25:52.559334Z","shell.execute_reply.started":"2023-04-29T05:25:52.541606Z"},"trusted":true},"outputs":[],"source":["truncate_len = 45\n","\n","def collate_fn(batch_data):\n","\n","    uids, iids, labels = [], [], []\n","    u_items, u_users, u_users_items, i_users = [], [], [], []\n","    u_items_len, u_users_len, i_users_len = [], [], []\n","\n","    for data, u_items_u, u_users_u, u_users_items_u, i_users_i in batch_data:\n","\n","        (uid, iid, label) = data\n","        uids.append(uid)\n","        iids.append(iid)\n","        labels.append(label)\n","\n","        # user-items\n","        if len(u_items_u) <= truncate_len:\n","            u_items.append(u_items_u)\n","        else:\n","            u_items.append(random.sample(u_items_u, truncate_len))\n","        u_items_len.append(min(len(u_items_u), truncate_len))\n","        \n","        # user-users and user-users-items\n","        if len(u_users_u) <= truncate_len:\n","            u_users.append(u_users_u)\n","            u_u_items = [] \n","            for uui in u_users_items_u:\n","                if len(uui) < truncate_len:\n","                    u_u_items.append(uui)\n","                else:\n","                    u_u_items.append(random.sample(uui, truncate_len))\n","            u_users_items.append(u_u_items)\n","        else:\n","            sample_index = random.sample(list(range(len(u_users_u))), truncate_len)\n","            u_users.append([u_users_u[si] for si in sample_index])\n","\n","            u_users_items_u_tr = [u_users_items_u[si] for si in sample_index]\n","            u_u_items = [] \n","            for uui in u_users_items_u_tr:\n","                if len(uui) < truncate_len:\n","                    u_u_items.append(uui)\n","                else:\n","                    u_u_items.append(random.sample(uui, truncate_len))\n","            u_users_items.append(u_u_items)\n","\n","        u_users_len.append(min(len(u_users_u), truncate_len))\t\n","\n","        # item-users\n","        if len(i_users_i) <= truncate_len:\n","            i_users.append(i_users_i)\n","        else:\n","            i_users.append(random.sample(i_users_i, truncate_len))\n","        i_users_len.append(min(len(i_users_i), truncate_len))\n","\n","    batch_size = len(batch_data)\n","\n","    # padding\n","    u_items_maxlen = max(u_items_len)\n","    u_users_maxlen = max(u_users_len)\n","    i_users_maxlen = max(i_users_len)\n","    \n","    u_item_pad = torch.zeros([batch_size, u_items_maxlen, 2], dtype=torch.long)\n","    for i, ui in enumerate(u_items):\n","        u_item_pad[i, :len(ui), :] = torch.LongTensor(ui)\n","    \n","    u_user_pad = torch.zeros([batch_size, u_users_maxlen], dtype=torch.long)\n","    for i, uu in enumerate(u_users):\n","        u_user_pad[i, :len(uu)] = torch.LongTensor(uu)\n","    \n","    u_user_item_pad = torch.zeros([batch_size, u_users_maxlen, u_items_maxlen, 2], dtype=torch.long)\n","    for i, uu_items in enumerate(u_users_items):\n","        for j, ui in enumerate(uu_items):\n","            u_user_item_pad[i, j, :len(ui), :] = torch.LongTensor(ui)\n","\n","    i_user_pad = torch.zeros([batch_size, i_users_maxlen, 2], dtype=torch.long)\n","    for i, iu in enumerate(i_users):\n","        i_user_pad[i, :len(iu), :] = torch.LongTensor(iu)\n","\n","    uids = torch.LongTensor(uids)\n","    iids = torch.LongTensor(iids)\n","    labels = torch.FloatTensor(labels)\n","\n","    return uids, iids, labels, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:25:52.562299Z","iopub.status.busy":"2023-04-29T05:25:52.561931Z","iopub.status.idle":"2023-04-29T05:25:52.599092Z","shell.execute_reply":"2023-04-29T05:25:52.598103Z","shell.execute_reply.started":"2023-04-29T05:25:52.562263Z"},"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(MLP, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, input_dim//2, bias=True),\n","            nn.ReLU(),\n","            nn.Linear(input_dim//2, output_dim, bias=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n","\n","class Aggregator(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(Aggregator, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, output_dim, bias=True),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n","\n","\n","class UserModel(nn.Module):\n","    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n","        super(UserModel, self).__init__()\n","        self.emb_dim = emb_dim\n","        self.user_emb = user_emb\n","        self.item_emb = item_emb\n","        self.rating_emb = rating_emb\n","\n","        self.g_v = MLP(2*self.emb_dim, self.emb_dim)\n","        \n","        self.user_item_attn = MLP(2*self.emb_dim, 1)\n","        self.aggr_items = Aggregator(self.emb_dim, self.emb_dim)\n","\n","        self.user_user_attn = MLP(2*self.emb_dim, 1)\n","        self.aggr_neighbors = Aggregator(self.emb_dim, self.emb_dim)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(2*self.emb_dim, self.emb_dim, bias = True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n","            nn.ReLU()\n","        )\n","\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.eps = 1e-10\n","\n","    def forward(self, uids, u_item_pad, u_user_pad, u_user_item_pad):\n","\n","        q_a = self.item_emb(u_item_pad[:,:,0])\n","        u_item_er = self.rating_emb(u_item_pad[:,:,1])\n","        x_ia = self.g_v(torch.cat([q_a, u_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a.size())\n","        mask_u = torch.where(u_item_pad[:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        p_i = mask_u.unsqueeze(2).expand_as(x_ia) * self.user_emb(uids).unsqueeze(1).expand_as(x_ia)\n","        alpha = self.user_item_attn(torch.cat([x_ia, p_i], dim=2).view(-1, 2*self.emb_dim)).view(mask_u.size())\n","        alpha = torch.exp(alpha)*mask_u\n","        alpha = alpha / (torch.sum(alpha, 1).unsqueeze(1).expand_as(alpha) + self.eps)\n","        h_iI = self.aggr_items(torch.sum(alpha.unsqueeze(2).expand_as(x_ia) * x_ia, 1))\n","\n","\n","        q_a_s = self.item_emb(u_user_item_pad[:,:,:,0])\n","        u_user_item_er = self.rating_emb(u_user_item_pad[:,:,:,1])\n","        x_ia_s = self.g_v(torch.cat([q_a_s, u_user_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a_s.size())\n","        mask_s = torch.where(u_user_item_pad[:,:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        p_i_s = mask_s.unsqueeze(3).expand_as(x_ia_s) * self.user_emb(u_user_pad).unsqueeze(2).expand_as(x_ia_s)\n","        alpha_s = self.user_item_attn(torch.cat([x_ia_s, p_i_s], dim=3).view(-1, 2*self.emb_dim)).view(mask_s.size())\n","        alpha_s = torch.exp(alpha_s)*mask_s\n","        alpha_s = alpha_s / (torch.sum(alpha_s, 2).unsqueeze(2).expand_as(alpha_s) + self.eps)\n","        h_oI_temp = torch.sum(alpha_s.unsqueeze(3).expand_as(x_ia_s) * x_ia_s, 2)\n","        h_oI = self.aggr_items(h_oI_temp.view(-1, self.emb_dim)).view(h_oI_temp.size())\n","        \n","        beta = self.user_user_attn(torch.cat([h_oI, self.user_emb(u_user_pad)], dim = 2).view(-1, 2 * self.emb_dim)).view(u_user_pad.size())\n","        mask_su = torch.where(u_user_pad > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        beta = torch.exp(beta) * mask_su\n","        beta = beta / (torch.sum(beta, 1).unsqueeze(1).expand_as(beta) + self.eps)\n","        h_iS = self.aggr_neighbors(torch.sum(beta.unsqueeze(2).expand_as(h_oI) * h_oI, 1))\n","\n","        h_i = self.mlp(torch.cat([h_iI, h_iS], dim = 1))\n","        return h_i\n","\n","\n","class ItemModel(nn.Module):\n","    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n","        super(ItemModel, self).__init__()\n","        self.emb_dim = emb_dim\n","        self.user_emb = user_emb\n","        self.item_emb = item_emb\n","        self.rating_emb = rating_emb\n","\n","        self.g_u = MLP(2*self.emb_dim, self.emb_dim)\n","\n","        self.item_users_attn = MLP(2*self.emb_dim, 1)\n","        self.aggr_users = Aggregator(self.emb_dim, self.emb_dim)\n","\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.eps = 1e-10\n","    \n","    def forward(self, iids, i_user_pad):\n","\n","        p_t = self.user_emb(i_user_pad[:,:,0])\n","        i_user_er = self.rating_emb(i_user_pad[:,:,1])\n","        mask_i = torch.where(i_user_pad[:,:,0] > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n","        f_jt = self.g_u(torch.cat([p_t, i_user_er], dim = 2).view(-1, 2 * self.emb_dim)).view(p_t.size())\n","        q_j = mask_i.unsqueeze(2).expand_as(f_jt) * self.item_emb(iids).unsqueeze(1).expand_as(f_jt)\n","        mu_jt = self.item_users_attn(torch.cat([f_jt, q_j], dim = 2).view(-1, 2 * self.emb_dim)).view(mask_i.size())\n","        mu_jt = torch.exp(mu_jt) * mask_i\n","        mu_jt = mu_jt / (torch.sum(mu_jt, 1).unsqueeze(1).expand_as(mu_jt) + self.eps)\n","        \n","        z_j = self.aggr_users(torch.sum(mu_jt.unsqueeze(2).expand_as(f_jt) * f_jt, 1))\n","        return z_j\n","        \n","    \n","class GraphRec(nn.Module):\n","    def __init__(self, n_users, n_items, n_ratings, emb_dim = 64):\n","        super(GraphRec, self).__init__()\n","        self.n_users = n_users\n","        self.n_items = n_items\n","        self.n_ratings = n_ratings\n","        self.emb_dim = emb_dim\n","\n","        self.user_emb = nn.Embedding(self.n_users, self.emb_dim, padding_idx=0)\n","        self.item_emb = nn.Embedding(self.n_items, self.emb_dim, padding_idx=0)\n","        self.rating_emb = nn.Embedding(self.n_ratings, self.emb_dim, padding_idx=0)\n","\n","        self.user_model = UserModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n","        self.item_model = ItemModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(2*self.emb_dim, self.emb_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n","            nn.ReLU(),\n","            nn.Linear(self.emb_dim, 1)\n","        )\n","\n","    def forward(self, uids, iids, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad):\n","\n","        h_i = self.user_model(uids, u_item_pad, u_user_pad, u_user_item_pad)\n","        z_j = self.item_model(iids, i_user_pad)\n","\n","        r_ij = self.mlp(torch.cat([h_i, z_j], dim=1))\n","        return r_ij\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:26:30.217741Z","iopub.status.busy":"2023-04-29T05:26:30.216613Z","iopub.status.idle":"2023-04-29T05:26:30.316444Z","shell.execute_reply":"2023-04-29T05:26:30.315175Z","shell.execute_reply.started":"2023-04-29T05:26:30.217685Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["device - cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('device - ' + str(device))\n","batch_size = 128\n","embed_dim = 64\n","learning_rate = 0.001\n","n_epochs = 20"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:26:34.427740Z","iopub.status.busy":"2023-04-29T05:26:34.426767Z","iopub.status.idle":"2023-04-29T05:26:37.172820Z","shell.execute_reply":"2023-04-29T05:26:37.171747Z","shell.execute_reply.started":"2023-04-29T05:26:34.427683Z"},"trusted":true},"outputs":[],"source":["with open('/kaggle/input/nam-project-2/dataset.pkl', 'rb') as f:\n","    train_set = pickle.load(f)\n","    valid_set = pickle.load(f)\n","    test_set = pickle.load(f)\n","\n","with open('/kaggle/input/nam-project-2/list.pkl', 'rb') as f:\n","    u_items_list = pickle.load(f)\n","    u_users_list = pickle.load(f)\n","    u_users_items_list = pickle.load(f)\n","    i_users_list = pickle.load(f)\n","    (user_count, item_count, rate_count) = pickle.load(f)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:26:40.795637Z","iopub.status.busy":"2023-04-29T05:26:40.795185Z","iopub.status.idle":"2023-04-29T05:26:40.801115Z","shell.execute_reply":"2023-04-29T05:26:40.800014Z","shell.execute_reply.started":"2023-04-29T05:26:40.795598Z"},"trusted":true},"outputs":[],"source":["train_data = GraphDataset(train_set, u_items_list, u_users_list, u_users_items_list, i_users_list)\n","valid_data = GraphDataset(valid_set, u_items_list, u_users_list, u_users_items_list, i_users_list)\n","test_data = GraphDataset(test_set, u_items_list, u_users_list, u_users_items_list, i_users_list)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:26:46.732651Z","iopub.status.busy":"2023-04-29T05:26:46.732278Z","iopub.status.idle":"2023-04-29T05:26:46.738701Z","shell.execute_reply":"2023-04-29T05:26:46.737532Z","shell.execute_reply.started":"2023-04-29T05:26:46.732619Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n","valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n","test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:26:55.011543Z","iopub.status.busy":"2023-04-29T05:26:55.010570Z","iopub.status.idle":"2023-04-29T05:26:55.019731Z","shell.execute_reply":"2023-04-29T05:26:55.018559Z","shell.execute_reply.started":"2023-04-29T05:26:55.011488Z"},"trusted":true},"outputs":[{"data":{"text/plain":["5704"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(train_loader)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:26:58.144425Z","iopub.status.busy":"2023-04-29T05:26:58.143954Z","iopub.status.idle":"2023-04-29T05:27:01.512112Z","shell.execute_reply":"2023-04-29T05:27:01.510980Z","shell.execute_reply.started":"2023-04-29T05:26:58.144388Z"},"trusted":true},"outputs":[],"source":["model = GraphRec(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T05:27:06.826268Z","iopub.status.busy":"2023-04-29T05:27:06.825666Z","iopub.status.idle":"2023-04-29T05:27:06.832352Z","shell.execute_reply":"2023-04-29T05:27:06.831245Z","shell.execute_reply.started":"2023-04-29T05:27:06.826222Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.RMSprop(model.parameters(), learning_rate)\n","criterion = nn.MSELoss()\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 4, gamma = 0.1)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T06:05:26.824903Z","iopub.status.busy":"2023-04-29T06:05:26.823885Z","iopub.status.idle":"2023-04-29T10:20:33.269854Z","shell.execute_reply":"2023-04-29T10:20:33.267632Z","shell.execute_reply.started":"2023-04-29T06:05:26.824862Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:22<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 validation: MAE: 1.4481, RMSE: 3.8638, Best MAE: 1.4481\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:20<00:00, 10.18it/s]\n","100%|██████████| 713/713 [00:47<00:00, 14.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 validation: MAE: 1.3020, RMSE: 3.3727, Best MAE: 1.3020\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:24<00:00, 10.10it/s]\n","100%|██████████| 713/713 [00:49<00:00, 14.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 validation: MAE: 1.2201, RMSE: 3.1745, Best MAE: 1.2201\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.17it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 validation: MAE: 1.2091, RMSE: 3.1593, Best MAE: 1.2091\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 validation: MAE: 1.2114, RMSE: 3.1570, Best MAE: 1.2091\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:22<00:00, 10.14it/s]\n","100%|██████████| 713/713 [00:49<00:00, 14.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 validation: MAE: 1.2156, RMSE: 3.1635, Best MAE: 1.2091\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:22<00:00, 10.14it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 validation: MAE: 1.2097, RMSE: 3.1638, Best MAE: 1.2091\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:20<00:00, 10.17it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 validation: MAE: 1.2075, RMSE: 3.1642, Best MAE: 1.2075\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:18<00:00, 10.21it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 validation: MAE: 1.2089, RMSE: 3.1640, Best MAE: 1.2075\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:19<00:00, 10.20it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 validation: MAE: 1.2070, RMSE: 3.1638, Best MAE: 1.2070\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:20<00:00, 10.19it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 validation: MAE: 1.2137, RMSE: 3.1650, Best MAE: 1.2070\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:19<00:00, 10.20it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 validation: MAE: 1.2067, RMSE: 3.1641, Best MAE: 1.2067\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:22<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 validation: MAE: 1.2070, RMSE: 3.1642, Best MAE: 1.2067\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:22<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 validation: MAE: 1.2070, RMSE: 3.1645, Best MAE: 1.2067\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:22<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 validation: MAE: 1.2071, RMSE: 3.1645, Best MAE: 1.2067\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:23<00:00, 10.12it/s]\n","100%|██████████| 713/713 [00:49<00:00, 14.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 validation: MAE: 1.2065, RMSE: 3.1645, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 validation: MAE: 1.2067, RMSE: 3.1647, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:20<00:00, 10.17it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 validation: MAE: 1.2068, RMSE: 3.1650, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.17it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 validation: MAE: 1.2068, RMSE: 3.1652, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:20<00:00, 10.17it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 validation: MAE: 1.2068, RMSE: 3.1651, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 1964/5704 [03:13<07:39,  8.15it/s]IOPub message rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_msg_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n","100%|██████████| 5704/5704 [09:20<00:00, 10.17it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 validation: MAE: 1.2069, RMSE: 3.1649, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 validation: MAE: 1.2072, RMSE: 3.1654, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.15it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 validation: MAE: 1.2070, RMSE: 3.1649, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:21<00:00, 10.16it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24 validation: MAE: 1.2070, RMSE: 3.1650, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5704/5704 [09:19<00:00, 10.20it/s]\n","100%|██████████| 713/713 [00:48<00:00, 14.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25 validation: MAE: 1.2067, RMSE: 3.1647, Best MAE: 1.2065\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 452/5704 [00:44<08:34, 10.20it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/478104642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_users_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2311572414.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, uids, iids, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_item_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_user_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_user_item_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_user_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mh_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_item_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_user_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_user_item_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mz_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_user_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2311572414.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, uids, u_item_pad, u_user_pad, u_user_item_pad)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_user_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_oI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_user_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_user_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mmask_su\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_user_pad\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_su\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(n_epochs):\n","\n","    model.train()\n","    s_loss = 0\n","    for i, (uids, iids, labels, u_items, u_users, u_users_items, i_users) in tqdm(enumerate(train_loader), total=len(train_loader)):\n","        uids = uids.to(device)\n","        iids = iids.to(device)\n","        labels = labels.to(device)\n","        u_items = u_items.to(device)\n","        u_users = u_users.to(device)\n","        u_users_items = u_users_items.to(device)\n","        i_users = i_users.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(uids, iids, u_items, u_users, u_users_items, i_users)\n","        loss = criterion(outputs, labels.unsqueeze(1))\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_val = loss.item()\n","        s_loss += loss_val\n","\n","        iter_num = epoch * len(train_loader) + i + 1\n","\n","    # Validate step\n","    model.eval()\n","    errors = []\n","    with torch.no_grad():\n","        for uids, iids, labels, u_items, u_users, u_users_items, i_users in tqdm(valid_loader):\n","            uids = uids.to(device)\n","            iids = iids.to(device)\n","            labels = labels.to(device)\n","            u_items = u_items.to(device)\n","            u_users = u_users.to(device)\n","            u_users_items = u_users_items.to(device)\n","            i_users = i_users.to(device)\n","            preds = model(uids, iids, u_items, u_users, u_users_items, i_users)\n","            error = torch.abs(preds.squeeze(1) - labels)\n","            errors.extend(error.data.cpu().numpy().tolist())\n","    \n","    mae = np.mean(errors)\n","    rmse = np.sqrt(np.mean(np.power(errors, 2)))\n","\n","    scheduler.step()\n","\n","    ckpt_dict = {\n","        'epoch': epoch + 1,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict()\n","    }\n","    torch.save(ckpt_dict, 'latest_checkpoint.pth')\n","\n","    if epoch == 0:\n","        best_mae = mae\n","    elif mae < best_mae:\n","        best_mae = mae\n","        torch.save(ckpt_dict, 'best_checkpoint_{}.pth'.format(embed_dim))\n","\n","    print('Epoch {} validation: MAE: {:.4f}, RMSE: {:.4f}, Best MAE: {:.4f}'.format(epoch+1, mae, rmse, best_mae))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T10:20:50.174767Z","iopub.status.busy":"2023-04-29T10:20:50.174102Z","iopub.status.idle":"2023-04-29T10:20:50.525273Z","shell.execute_reply":"2023-04-29T10:20:50.524184Z","shell.execute_reply.started":"2023-04-29T10:20:50.174728Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["embed_dim = 64\n","checkpoint = torch.load('best_checkpoint_{}.pth'.format(embed_dim))\n","model = GraphRec(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)\n","model.load_state_dict(checkpoint['state_dict'])\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T10:21:49.760774Z","iopub.status.busy":"2023-04-29T10:21:49.760405Z","iopub.status.idle":"2023-04-29T10:22:37.937404Z","shell.execute_reply":"2023-04-29T10:22:37.936156Z","shell.execute_reply.started":"2023-04-29T10:21:49.760741Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 713/713 [00:48<00:00, 14.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test: MAE: 1.2084, RMSE: 3.1649\n"]}],"source":["model.eval()\n","test_errors = []\n","with torch.no_grad():\n","    for uids, iids, labels, u_items, u_users, u_users_items, i_users in tqdm(test_loader):\n","        uids = uids.to(device)\n","        iids = iids.to(device)\n","        labels = labels.to(device)\n","        u_items = u_items.to(device)\n","        u_users = u_users.to(device)\n","        u_users_items = u_users_items.to(device)\n","        i_users = i_users.to(device)\n","        preds = model(uids, iids, u_items, u_users, u_users_items, i_users)\n","        error = torch.abs(preds.squeeze(1) - labels)\n","        test_errors.extend(error.data.cpu().numpy().tolist())\n","\n","test_mae = np.mean(test_errors)\n","test_rmse = np.sqrt(np.mean(np.power(test_errors, 2)))\n","print('Test: MAE: {:.4f}, RMSE: {:.4f}'.format(test_mae, test_rmse))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
